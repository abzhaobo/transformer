{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:19:24.138672Z",
     "start_time": "2022-01-26T13:19:21.340512Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, SGDRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "# import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:27:21.026948Z",
     "start_time": "2022-01-26T13:26:23.741672Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/initial_data.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:27:31.811565Z",
     "start_time": "2022-01-26T13:27:31.808565Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在94个x之外的列元素\n",
    "extra = ['permno','DATE','mve0','prc','RET','SHROUT','sic2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:27:39.366997Z",
     "start_time": "2022-01-26T13:27:35.460774Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1972=df[df['DATE']>=19720101].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:27:50.778650Z",
     "start_time": "2022-01-26T13:27:50.775650Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = df_1972.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:29:32.691479Z",
     "start_time": "2022-01-26T13:28:06.072525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "df_dropna = df_1972.groupby('DATE',as_index=False)[cols].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:31:30.216201Z",
     "start_time": "2022-01-26T13:31:30.209201Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    # exclude the the information columns\n",
    "    col_names = df.columns.values.tolist()\n",
    "    list_to_remove = ['permno', 'DATE', 'date', 'datadate', 'gvkey', 'sic', 'count', 'exchcd', 'shrcd', 'ffi49', 'ret',\n",
    "                      'retadj', 'retx', 'lag_me']\n",
    "    col_names = list(set(col_names).difference(set(list_to_remove)))\n",
    "    for col_name in col_names:\n",
    "        print('processing %s' % col_name)\n",
    "        # count the non-missing number of factors, we only count non-missing values\n",
    "        unique_count = df.dropna(subset=['%s' % col_name]).groupby(['DATE'])['%s' % col_name].unique().apply(len)\n",
    "        unique_count = pd.DataFrame(unique_count).reset_index()\n",
    "        unique_count.columns = ['DATE', 'count']\n",
    "        df = pd.merge(df, unique_count, how='left', on=['DATE'])\n",
    "        # ranking, and then standardize the data\n",
    "        df['%s_rank' % col_name] = df.groupby(['DATE'])['%s' % col_name].rank(method='dense')\n",
    "        df['rank_%s' % col_name] = (df['%s_rank' % col_name] - 1) / (df['count'] - 1) * 2 - 1\n",
    "        df = df.drop(['%s_rank' % col_name, '%s' % col_name, 'count'], axis=1)\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:56:10.734882Z",
     "start_time": "2022-01-26T13:31:36.672571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing roavol\n",
      "processing retvol\n",
      "processing grltnoa\n",
      "processing sp\n",
      "processing RET\n",
      "processing lgr\n",
      "processing depr\n",
      "processing roic\n",
      "processing stdcf\n",
      "processing mve0\n",
      "processing rd_sale\n",
      "processing std_turn\n",
      "processing pchgm_pchsale\n",
      "processing ill\n",
      "processing cinvest\n",
      "processing bm\n",
      "processing pchcurrat\n",
      "processing mvel1\n",
      "processing pctacc\n",
      "processing absacc\n",
      "processing cashdebt\n",
      "processing roeq\n",
      "processing chpmia\n",
      "processing mom36m\n",
      "processing agr\n",
      "processing pchsale_pchrect\n",
      "processing idiovol\n",
      "processing mve_ia\n",
      "processing ms\n",
      "processing gma\n",
      "processing rd\n",
      "processing invest\n",
      "processing age\n",
      "processing pchsaleinv\n",
      "processing baspread\n",
      "processing securedind\n",
      "processing rsup\n",
      "processing prc\n",
      "processing orgcap\n",
      "processing salecash\n",
      "processing mom1m\n",
      "processing saleinv\n",
      "processing pchsale_pchxsga\n",
      "processing pchsale_pchinvt\n",
      "processing currat\n",
      "processing pchcapx_ia\n",
      "processing pricedelay\n",
      "processing roaq\n",
      "processing tang\n",
      "processing herf\n",
      "processing cfp\n",
      "processing std_dolvol\n",
      "processing ear\n",
      "processing mom6m\n",
      "processing betasq\n",
      "processing dy\n",
      "processing salerec\n",
      "processing turn\n",
      "processing grcapx\n",
      "processing divi\n",
      "processing convind\n",
      "processing acc\n",
      "processing chempia\n",
      "processing aeavol\n",
      "processing zerotrade\n",
      "processing chinv\n",
      "processing cfp_ia\n",
      "processing beta\n",
      "processing dolvol\n",
      "processing operprof\n",
      "processing mom12m\n",
      "processing chmom\n",
      "processing SHROUT\n",
      "processing quick\n",
      "processing stdacc\n",
      "processing nincr\n",
      "processing ps\n",
      "processing realestate\n",
      "processing secured\n",
      "processing chcsho\n",
      "processing pchdepr\n",
      "processing chtx\n",
      "processing lev\n",
      "processing indmom\n",
      "processing cashpr\n",
      "processing divo\n",
      "processing hire\n",
      "processing sic2\n",
      "processing sgr\n",
      "processing rd_mve\n",
      "processing ep\n",
      "processing tb\n",
      "processing maxret\n",
      "processing sin\n",
      "processing egr\n",
      "processing bm_ia\n",
      "processing cash\n",
      "processing pchquick\n",
      "processing chatoia\n"
     ]
    }
   ],
   "source": [
    "df_rank = standardize(df_dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:56:12.749997Z",
     "start_time": "2022-01-26T13:56:10.736882Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rank = df_rank.drop(columns=['rank_mve0','rank_prc','rank_SHROUT','rank_sic2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:56:14.390091Z",
     "start_time": "2022-01-26T13:56:12.750997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>rank_roavol</th>\n",
       "      <th>rank_retvol</th>\n",
       "      <th>rank_grltnoa</th>\n",
       "      <th>rank_sp</th>\n",
       "      <th>rank_RET</th>\n",
       "      <th>rank_lgr</th>\n",
       "      <th>rank_depr</th>\n",
       "      <th>rank_roic</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_rd_mve</th>\n",
       "      <th>rank_ep</th>\n",
       "      <th>rank_tb</th>\n",
       "      <th>rank_maxret</th>\n",
       "      <th>rank_sin</th>\n",
       "      <th>rank_egr</th>\n",
       "      <th>rank_bm_ia</th>\n",
       "      <th>rank_cash</th>\n",
       "      <th>rank_pchquick</th>\n",
       "      <th>rank_chatoia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>19720131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.966346</td>\n",
       "      <td>0.529197</td>\n",
       "      <td>-0.195598</td>\n",
       "      <td>-0.476645</td>\n",
       "      <td>0.285866</td>\n",
       "      <td>-0.629517</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.610487</td>\n",
       "      <td>0.212274</td>\n",
       "      <td>-0.537825</td>\n",
       "      <td>-0.863910</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.418202</td>\n",
       "      <td>0.126789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401124</td>\n",
       "      <td>0.662705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014</td>\n",
       "      <td>19720131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>-0.883212</td>\n",
       "      <td>0.378689</td>\n",
       "      <td>0.578556</td>\n",
       "      <td>-0.263549</td>\n",
       "      <td>0.209160</td>\n",
       "      <td>-0.923913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074906</td>\n",
       "      <td>-0.892354</td>\n",
       "      <td>-0.482270</td>\n",
       "      <td>0.770887</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.867822</td>\n",
       "      <td>0.622699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.787640</td>\n",
       "      <td>-0.761177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10057</td>\n",
       "      <td>19720131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.154577</td>\n",
       "      <td>0.402335</td>\n",
       "      <td>0.616366</td>\n",
       "      <td>-0.061578</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074906</td>\n",
       "      <td>0.469819</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.016365</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.563380</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714607</td>\n",
       "      <td>0.231466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10065</td>\n",
       "      <td>19720131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.736378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>-0.169851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.047281</td>\n",
       "      <td>-0.662360</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10102</td>\n",
       "      <td>19720131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.371795</td>\n",
       "      <td>-0.423358</td>\n",
       "      <td>0.022511</td>\n",
       "      <td>0.097665</td>\n",
       "      <td>-0.088204</td>\n",
       "      <td>-0.265140</td>\n",
       "      <td>-0.309783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.194165</td>\n",
       "      <td>-0.815603</td>\n",
       "      <td>-0.018088</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.595883</td>\n",
       "      <td>0.753579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247191</td>\n",
       "      <td>-0.488398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717436</th>\n",
       "      <td>93423</td>\n",
       "      <td>20201231</td>\n",
       "      <td>0.521326</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>0.417193</td>\n",
       "      <td>-0.150362</td>\n",
       "      <td>0.471229</td>\n",
       "      <td>0.256082</td>\n",
       "      <td>-0.539853</td>\n",
       "      <td>0.858152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998782</td>\n",
       "      <td>0.266615</td>\n",
       "      <td>-0.185150</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.363803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.908430</td>\n",
       "      <td>0.893571</td>\n",
       "      <td>-0.394495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717437</th>\n",
       "      <td>93426</td>\n",
       "      <td>20201231</td>\n",
       "      <td>-0.532192</td>\n",
       "      <td>0.423032</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.140713</td>\n",
       "      <td>0.261832</td>\n",
       "      <td>0.323045</td>\n",
       "      <td>0.154324</td>\n",
       "      <td>0.672337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191230</td>\n",
       "      <td>0.291113</td>\n",
       "      <td>0.070919</td>\n",
       "      <td>0.725809</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.327762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457581</td>\n",
       "      <td>-0.801729</td>\n",
       "      <td>-0.731786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717438</th>\n",
       "      <td>93427</td>\n",
       "      <td>20201231</td>\n",
       "      <td>-0.738658</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>-0.500632</td>\n",
       "      <td>0.334227</td>\n",
       "      <td>0.578141</td>\n",
       "      <td>0.150929</td>\n",
       "      <td>-0.021481</td>\n",
       "      <td>0.745616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260658</td>\n",
       "      <td>0.517852</td>\n",
       "      <td>-0.831509</td>\n",
       "      <td>-0.411805</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.556542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641799</td>\n",
       "      <td>0.350621</td>\n",
       "      <td>0.554776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717439</th>\n",
       "      <td>93434</td>\n",
       "      <td>20201231</td>\n",
       "      <td>0.325727</td>\n",
       "      <td>0.154274</td>\n",
       "      <td>-0.704172</td>\n",
       "      <td>0.519164</td>\n",
       "      <td>0.527749</td>\n",
       "      <td>-0.878629</td>\n",
       "      <td>0.305257</td>\n",
       "      <td>0.596964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323995</td>\n",
       "      <td>-0.594475</td>\n",
       "      <td>0.742980</td>\n",
       "      <td>0.481738</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.652128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.417183</td>\n",
       "      <td>0.719611</td>\n",
       "      <td>0.745818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717440</th>\n",
       "      <td>93436</td>\n",
       "      <td>20201231</td>\n",
       "      <td>-0.035045</td>\n",
       "      <td>0.306019</td>\n",
       "      <td>0.388748</td>\n",
       "      <td>-0.277406</td>\n",
       "      <td>0.798774</td>\n",
       "      <td>0.111169</td>\n",
       "      <td>-0.325608</td>\n",
       "      <td>-0.470296</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354446</td>\n",
       "      <td>-0.364608</td>\n",
       "      <td>-0.622085</td>\n",
       "      <td>0.356067</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.774876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.829281</td>\n",
       "      <td>0.508365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3717441 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         permno      DATE  rank_roavol  rank_retvol  rank_grltnoa   rank_sp  \\\n",
       "0         10006  19720131     0.000000    -0.966346      0.529197 -0.195598   \n",
       "1         10014  19720131     0.000000     0.894231     -0.883212  0.378689   \n",
       "2         10057  19720131     0.000000     0.016827      0.018248  0.154577   \n",
       "3         10065  19720131     0.000000    -0.736378      0.000000  0.009505   \n",
       "4         10102  19720131     0.000000    -0.371795     -0.423358  0.022511   \n",
       "...         ...       ...          ...          ...           ...       ...   \n",
       "3717436   93423  20201231     0.521326     0.616928      0.417193 -0.150362   \n",
       "3717437   93426  20201231    -0.532192     0.423032      0.549937  0.140713   \n",
       "3717438   93427  20201231    -0.738658    -0.490137     -0.500632  0.334227   \n",
       "3717439   93434  20201231     0.325727     0.154274     -0.704172  0.519164   \n",
       "3717440   93436  20201231    -0.035045     0.306019      0.388748 -0.277406   \n",
       "\n",
       "         rank_RET  rank_lgr  rank_depr  rank_roic  ...  rank_rd_mve   rank_ep  \\\n",
       "0       -0.476645  0.285866  -0.629517   0.086957  ...    -0.610487  0.212274   \n",
       "1        0.578556 -0.263549   0.209160  -0.923913  ...    -0.074906 -0.892354   \n",
       "2        0.402335  0.616366  -0.061578  -0.125000  ...    -0.074906  0.469819   \n",
       "3       -0.169851  0.000000   0.009669   0.000000  ...    -0.074906  0.000000   \n",
       "4        0.097665 -0.088204  -0.265140  -0.309783  ...     0.067416  0.194165   \n",
       "...           ...       ...        ...        ...  ...          ...       ...   \n",
       "3717436  0.471229  0.256082  -0.539853   0.858152  ...    -0.998782  0.266615   \n",
       "3717437  0.261832  0.323045   0.154324   0.672337  ...    -0.191230  0.291113   \n",
       "3717438  0.578141  0.150929  -0.021481   0.745616  ...    -0.260658  0.517852   \n",
       "3717439  0.527749 -0.878629   0.305257   0.596964  ...     0.323995 -0.594475   \n",
       "3717440  0.798774  0.111169  -0.325608  -0.470296  ...    -0.354446 -0.364608   \n",
       "\n",
       "          rank_tb  rank_maxret  rank_sin  rank_egr  rank_bm_ia  rank_cash  \\\n",
       "0       -0.537825    -0.863910      -1.0 -0.418202    0.126789   0.000000   \n",
       "1       -0.482270     0.770887      -1.0 -0.867822    0.622699   0.000000   \n",
       "2        0.393617     0.016365      -1.0 -0.563380    0.710634   0.000000   \n",
       "3       -0.047281    -0.662360      -1.0 -0.001083    0.008180   0.000000   \n",
       "4       -0.815603    -0.018088      -1.0 -0.595883    0.753579   0.000000   \n",
       "...           ...          ...       ...       ...         ...        ...   \n",
       "3717436 -0.185150     0.786741      -1.0  0.363803    0.000000  -0.908430   \n",
       "3717437  0.070919     0.725809      -1.0  0.327762    0.000000   0.457581   \n",
       "3717438 -0.831509    -0.411805      -1.0  0.556542    0.000000   0.641799   \n",
       "3717439  0.742980     0.481738      -1.0  0.652128    0.000000  -0.417183   \n",
       "3717440 -0.622085     0.356067      -1.0  0.774876    0.000000   0.446809   \n",
       "\n",
       "         rank_pchquick  rank_chatoia  \n",
       "0             0.401124      0.662705  \n",
       "1            -0.787640     -0.761177  \n",
       "2             0.714607      0.231466  \n",
       "3             0.000000     -0.000566  \n",
       "4             0.247191     -0.488398  \n",
       "...                ...           ...  \n",
       "3717436       0.893571     -0.394495  \n",
       "3717437      -0.801729     -0.731786  \n",
       "3717438       0.350621      0.554776  \n",
       "3717439       0.719611      0.745818  \n",
       "3717440       0.829281      0.508365  \n",
       "\n",
       "[3717441 rows x 97 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T13:56:23.417607Z",
     "start_time": "2022-01-26T13:56:14.392091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [permno, DATE, rank_roavol, rank_retvol, rank_grltnoa, rank_sp, rank_RET, rank_lgr, rank_depr, rank_roic, rank_stdcf, rank_rd_sale, rank_std_turn, rank_pchgm_pchsale, rank_ill, rank_cinvest, rank_bm, rank_pchcurrat, rank_mvel1, rank_pctacc, rank_absacc, rank_cashdebt, rank_roeq, rank_chpmia, rank_mom36m, rank_agr, rank_pchsale_pchrect, rank_idiovol, rank_mve_ia, rank_ms, rank_gma, rank_rd, rank_invest, rank_age, rank_pchsaleinv, rank_baspread, rank_securedind, rank_rsup, rank_orgcap, rank_salecash, rank_mom1m, rank_saleinv, rank_pchsale_pchxsga, rank_pchsale_pchinvt, rank_currat, rank_pchcapx_ia, rank_pricedelay, rank_roaq, rank_tang, rank_herf, rank_cfp, rank_std_dolvol, rank_ear, rank_mom6m, rank_betasq, rank_dy, rank_salerec, rank_turn, rank_grcapx, rank_divi, rank_convind, rank_acc, rank_chempia, rank_aeavol, rank_zerotrade, rank_chinv, rank_cfp_ia, rank_beta, rank_dolvol, rank_operprof, rank_mom12m, rank_chmom, rank_quick, rank_stdacc, rank_nincr, rank_ps, rank_realestate, rank_secured, rank_chcsho, rank_pchdepr, rank_chtx, rank_lev, rank_indmom, rank_cashpr, rank_divo, rank_hire, rank_sgr, rank_rd_mve, rank_ep, rank_tb, rank_maxret, rank_sin, rank_egr, rank_bm_ia, rank_cash, rank_pchquick, rank_chatoia]\n",
      "\n",
      "[97 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_rank[df_rank.isnull().T.any()].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:33.423816Z",
     "start_time": "2022-01-26T14:16:33.420816Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = df_rank.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:34.342868Z",
     "start_time": "2022-01-26T14:16:34.338868Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_mon = ['rank_baspread','rank_beta','rank_betasq','rank_chmom','rank_dolvol','rank_idiovol','rank_ill','rank_indmom','rank_maxret','rank_mom12m','rank_mom1m','rank_mom36m','rank_mom6m','rank_mvel1','rank_pricedelay','rank_retvol','rank_std_dolvol','rank_std_turn','rank_turn','rank_zerotrade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:35.138914Z",
     "start_time": "2022-01-26T14:16:35.134914Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_qua = ['rank_aeavol','rank_cash','rank_chtx','rank_cinvest','rank_ear','rank_ms','rank_nincr','rank_roaq','rank_roavol','rank_roeq','rank_rsup','rank_stdacc','rank_stdcf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:36.000963Z",
     "start_time": "2022-01-26T14:16:35.997963Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_beyond94 = ['RET','permno','DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:36.638000Z",
     "start_time": "2022-01-26T14:16:36.635000Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_ann = list(set(cols)-set(cols_mon)-set(cols_qua)-set(cols_beyond94))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:43.921416Z",
     "start_time": "2022-01-26T14:16:37.268036Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rank[cols_mon] = df_rank[cols_mon].shift(1)\n",
    "df_rank[cols_qua] = df_rank[cols_qua].shift(5)\n",
    "df_rank[cols_ann] = df_rank[cols_ann].shift(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:16:47.898644Z",
     "start_time": "2022-01-26T14:16:45.539509Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rank = df_rank.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:17:37.853501Z",
     "start_time": "2022-01-26T14:17:33.707264Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rank['DATE'] = df_rank['DATE'].astype(str).str.slice(start = 0, stop = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:18:12.989511Z",
     "start_time": "2022-01-26T14:18:12.569487Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rank['DATE'] = df_rank['DATE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:18:17.980796Z",
     "start_time": "2022-01-26T14:18:14.224581Z"
    }
   },
   "outputs": [],
   "source": [
    "df_rank=df_rank[df_rank['DATE']>=197501].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:18:20.945966Z",
     "start_time": "2022-01-26T14:18:19.510884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>rank_roavol</th>\n",
       "      <th>rank_retvol</th>\n",
       "      <th>rank_grltnoa</th>\n",
       "      <th>rank_sp</th>\n",
       "      <th>rank_RET</th>\n",
       "      <th>rank_lgr</th>\n",
       "      <th>rank_depr</th>\n",
       "      <th>rank_roic</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_rd_mve</th>\n",
       "      <th>rank_ep</th>\n",
       "      <th>rank_tb</th>\n",
       "      <th>rank_maxret</th>\n",
       "      <th>rank_sin</th>\n",
       "      <th>rank_egr</th>\n",
       "      <th>rank_bm_ia</th>\n",
       "      <th>rank_cash</th>\n",
       "      <th>rank_pchquick</th>\n",
       "      <th>rank_chatoia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157936</th>\n",
       "      <td>10006</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.602465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.462989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251641</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.057424</td>\n",
       "      <td>0.715111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157937</th>\n",
       "      <td>10014</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.453519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.938391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251641</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.057424</td>\n",
       "      <td>-0.288703</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157938</th>\n",
       "      <td>10050</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.913553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.994271</td>\n",
       "      <td>-0.828046</td>\n",
       "      <td>0.957022</td>\n",
       "      <td>-0.863580</td>\n",
       "      <td>0.307832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251641</td>\n",
       "      <td>-0.910009</td>\n",
       "      <td>0.308189</td>\n",
       "      <td>0.702929</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.859884</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157939</th>\n",
       "      <td>10057</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.284535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.149425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251641</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.057424</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157940</th>\n",
       "      <td>10065</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.553432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.776552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251641</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>-0.057424</td>\n",
       "      <td>-0.108787</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717436</th>\n",
       "      <td>93423</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.373540</td>\n",
       "      <td>0.897488</td>\n",
       "      <td>0.409608</td>\n",
       "      <td>-0.327794</td>\n",
       "      <td>0.370106</td>\n",
       "      <td>0.787078</td>\n",
       "      <td>0.496326</td>\n",
       "      <td>-0.817325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438490</td>\n",
       "      <td>-0.675267</td>\n",
       "      <td>0.740124</td>\n",
       "      <td>0.799204</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.926352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687584</td>\n",
       "      <td>0.272285</td>\n",
       "      <td>0.815974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717437</th>\n",
       "      <td>93426</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>-0.525917</td>\n",
       "      <td>0.034575</td>\n",
       "      <td>0.596868</td>\n",
       "      <td>-0.836777</td>\n",
       "      <td>-0.932165</td>\n",
       "      <td>-0.533107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260658</td>\n",
       "      <td>-0.389627</td>\n",
       "      <td>0.742980</td>\n",
       "      <td>0.786741</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.452599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>-0.181524</td>\n",
       "      <td>-0.191581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717438</th>\n",
       "      <td>93427</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.423032</td>\n",
       "      <td>0.178255</td>\n",
       "      <td>0.116591</td>\n",
       "      <td>-0.559755</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>0.884115</td>\n",
       "      <td>-0.700079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>-0.570498</td>\n",
       "      <td>0.784864</td>\n",
       "      <td>0.725809</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.981718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.656942</td>\n",
       "      <td>0.977334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717439</th>\n",
       "      <td>93434</td>\n",
       "      <td>202012</td>\n",
       "      <td>-0.740288</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>-0.022246</td>\n",
       "      <td>-0.189990</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260658</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>-0.411805</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.405333</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.025904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717440</th>\n",
       "      <td>93436</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.507199</td>\n",
       "      <td>0.154274</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>-0.022246</td>\n",
       "      <td>-0.356486</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260658</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.481738</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.873418</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.025904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3559505 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         permno    DATE  rank_roavol  rank_retvol  rank_grltnoa   rank_sp  \\\n",
       "157936    10006  197501     0.009809     0.602465      0.000000  0.010026   \n",
       "157937    10014  197501     0.009809    -0.453519      0.000000  0.010026   \n",
       "157938    10050  197501     0.009809     0.913553      1.000000 -0.994271   \n",
       "157939    10057  197501     0.009809     0.284535      0.000000  0.010026   \n",
       "157940    10065  197501     0.009809    -0.553432      0.000000  0.010026   \n",
       "...         ...     ...          ...          ...           ...       ...   \n",
       "3717436   93423  202012     0.373540     0.897488      0.409608 -0.327794   \n",
       "3717437   93426  202012     0.010052     0.616928     -0.525917  0.034575   \n",
       "3717438   93427  202012     0.010052     0.423032      0.178255  0.116591   \n",
       "3717439   93434  202012    -0.740288    -0.490137     -0.004425 -0.022246   \n",
       "3717440   93436  202012     0.507199     0.154274     -0.004425 -0.022246   \n",
       "\n",
       "         rank_RET  rank_lgr  rank_depr  rank_roic  ...  rank_rd_mve   rank_ep  \\\n",
       "157936   0.462989  0.000000   0.011728   0.000000  ...    -0.251641  0.000288   \n",
       "157937  -0.938391  0.000000   0.011728   0.000000  ...    -0.251641  0.000288   \n",
       "157938  -0.828046  0.957022  -0.863580   0.307832  ...    -0.251641 -0.910009   \n",
       "157939  -0.149425  0.000000   0.011728   0.000000  ...    -0.251641  0.000288   \n",
       "157940  -0.776552  0.000000   0.011728   0.000000  ...    -0.251641  0.000288   \n",
       "...           ...       ...        ...        ...  ...          ...       ...   \n",
       "3717436  0.370106  0.787078   0.496326  -0.817325  ...     0.438490 -0.675267   \n",
       "3717437  0.596868 -0.836777  -0.932165  -0.533107  ...    -0.260658 -0.389627   \n",
       "3717438 -0.559755 -0.943500   0.884115  -0.700079  ...     0.755177 -0.570498   \n",
       "3717439 -0.189990 -0.001308   0.007914   0.004449  ...    -0.260658  0.002346   \n",
       "3717440 -0.356486 -0.001308   0.007914   0.004449  ...    -0.260658  0.002346   \n",
       "\n",
       "          rank_tb  rank_maxret  rank_sin  rank_egr  rank_bm_ia  rank_cash  \\\n",
       "157936  -0.057424     0.715111      -1.0  0.000000    0.005814   0.008000   \n",
       "157937  -0.057424    -0.288703      -1.0  0.000000    0.005814   0.008000   \n",
       "157938   0.308189     0.702929      -1.0  1.000000   -0.859884   0.008000   \n",
       "157939  -0.057424     0.644351      -1.0  0.000000    0.005814   0.008000   \n",
       "157940  -0.057424    -0.108787      -1.0  0.000000    0.005814   0.008000   \n",
       "...           ...          ...       ...       ...         ...        ...   \n",
       "3717436  0.740124     0.799204      -1.0 -0.926352    0.000000   0.687584   \n",
       "3717437  0.742980     0.786741      -1.0 -0.452599    0.000000   0.006194   \n",
       "3717438  0.784864     0.725809      -1.0  0.981718    0.000000   0.006194   \n",
       "3717439  0.004284    -0.411805      -1.0 -0.000783    0.000000  -0.405333   \n",
       "3717440  0.004284     0.481738      -1.0 -0.000783    0.000000  -0.873418   \n",
       "\n",
       "         rank_pchquick  rank_chatoia  \n",
       "157936        0.000000      0.000898  \n",
       "157937        0.000000      0.000898  \n",
       "157938       -1.000000      0.000898  \n",
       "157939        0.000000      0.000898  \n",
       "157940        0.000000      0.000898  \n",
       "...                ...           ...  \n",
       "3717436       0.272285      0.815974  \n",
       "3717437      -0.181524     -0.191581  \n",
       "3717438       0.656942      0.977334  \n",
       "3717439       0.001080     -0.025904  \n",
       "3717440       0.001080     -0.025904  \n",
       "\n",
       "[3559505 rows x 97 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加入宏观因子作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:42:38.675343Z",
     "start_time": "2022-01-26T14:42:38.661342Z"
    }
   },
   "outputs": [],
   "source": [
    "factors = pd.read_csv(\"../figure/factors_197501-201912_24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:19:41.062548Z",
     "start_time": "2022-01-26T14:19:41.056548Z"
    }
   },
   "outputs": [],
   "source": [
    "macro = pd.read_csv(\"../data/8fac_1985-2020.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:42:41.826523Z",
     "start_time": "2022-01-26T14:42:41.822523Z"
    }
   },
   "outputs": [],
   "source": [
    "factors = factors[['month','logDP','logEP','svar','b/m','ntis','tbl','tms','dfy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:42:43.156599Z",
     "start_time": "2022-01-26T14:42:43.152599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "factors['month'] = factors['month'].str.replace('-','').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:42:44.042650Z",
     "start_time": "2022-01-26T14:42:44.038650Z"
    }
   },
   "outputs": [],
   "source": [
    "factors = factors.rename(columns = {'month':'yyyymm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:42:45.051708Z",
     "start_time": "2022-01-26T14:42:45.047708Z"
    }
   },
   "outputs": [],
   "source": [
    "factors=factors[factors['yyyymm']<198501].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:44:21.538227Z",
     "start_time": "2022-01-26T14:44:21.534226Z"
    }
   },
   "outputs": [],
   "source": [
    "macro = pd.concat([factors,macro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:44:50.193866Z",
     "start_time": "2022-01-26T14:44:50.177865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymm</th>\n",
       "      <th>logDP</th>\n",
       "      <th>logEP</th>\n",
       "      <th>svar</th>\n",
       "      <th>b/m</th>\n",
       "      <th>ntis</th>\n",
       "      <th>tbl</th>\n",
       "      <th>tms</th>\n",
       "      <th>dfy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197501</td>\n",
       "      <td>-3.056152</td>\n",
       "      <td>-2.175255</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.980830</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197502</td>\n",
       "      <td>-3.107892</td>\n",
       "      <td>-2.250332</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.011652</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197503</td>\n",
       "      <td>-3.122977</td>\n",
       "      <td>-2.289002</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>0.972466</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197504</td>\n",
       "      <td>-3.165533</td>\n",
       "      <td>-2.354702</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.022496</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197505</td>\n",
       "      <td>-3.205074</td>\n",
       "      <td>-2.417766</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.897524</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>202008</td>\n",
       "      <td>-4.080892</td>\n",
       "      <td>-3.569975</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.235975</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>202009</td>\n",
       "      <td>-4.045576</td>\n",
       "      <td>-3.533379</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.241482</td>\n",
       "      <td>-0.005698</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>202010</td>\n",
       "      <td>-4.020767</td>\n",
       "      <td>-3.519301</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.253146</td>\n",
       "      <td>-0.001895</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0069</td>\n",
       "      <td>0.0109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>202011</td>\n",
       "      <td>-4.126172</td>\n",
       "      <td>-3.635623</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.226352</td>\n",
       "      <td>-0.005262</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>202012</td>\n",
       "      <td>-4.165889</td>\n",
       "      <td>-3.686452</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.219195</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>552 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     yyyymm     logDP     logEP      svar       b/m      ntis     tbl     tms  \\\n",
       "0    197501 -3.056152 -2.175255  0.004017  0.980830  0.008510  0.0626  0.0170   \n",
       "1    197502 -3.107892 -2.250332  0.002179  0.933902  0.011652  0.0550  0.0238   \n",
       "2    197503 -3.122977 -2.289002  0.002403  0.972466  0.020467  0.0549  0.0275   \n",
       "3    197504 -3.165533 -2.354702  0.002314  0.909489  0.022496  0.0561  0.0291   \n",
       "4    197505 -3.205074 -2.417766  0.001807  0.897524  0.022954  0.0523  0.0313   \n",
       "..      ...       ...       ...       ...       ...       ...     ...     ...   \n",
       "427  202008 -4.080892 -3.569975  0.000743  0.235975 -0.008504  0.0010  0.0055   \n",
       "428  202009 -4.045576 -3.533379  0.004907  0.241482 -0.005698  0.0011  0.0057   \n",
       "429  202010 -4.020767 -3.519301  0.003661  0.253146 -0.001895  0.0010  0.0069   \n",
       "430  202011 -4.126172 -3.635623  0.002492  0.226352 -0.005262  0.0009  0.0078   \n",
       "431  202012 -4.165889 -3.686452  0.000678  0.219195 -0.000094  0.0009  0.0084   \n",
       "\n",
       "        dfy  \n",
       "0    0.0198  \n",
       "1    0.0203  \n",
       "2    0.0181  \n",
       "3    0.0163  \n",
       "4    0.0179  \n",
       "..      ...  \n",
       "427  0.0102  \n",
       "428  0.0105  \n",
       "429  0.0109  \n",
       "430  0.0100  \n",
       "431  0.0090  \n",
       "\n",
       "[552 rows x 9 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:45:17.337418Z",
     "start_time": "2022-01-26T14:45:17.334418Z"
    }
   },
   "outputs": [],
   "source": [
    "mvs = macro.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:45:25.400879Z",
     "start_time": "2022-01-26T14:45:25.397879Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list(set(cols)-set(['DATE','permno','rank_RET']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T14:45:31.544231Z",
     "start_time": "2022-01-26T14:45:31.540230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T16:09:57.957013Z",
     "start_time": "2022-01-26T14:45:56.384651Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将公司层面变量和宏观因子相乘\n",
    "z_all = pd.DataFrame()\n",
    "\n",
    "for m in df_rank.groupby('DATE'):\n",
    "    z = pd.DataFrame(m[1])\n",
    "    month = z['DATE'].unique()[0]\n",
    "    for i in range(8):\n",
    "        xt = macro.loc[macro['yyyymm'] == int(month),mvs[i]].values[0]\n",
    "        for s in cols :\n",
    "            z[mvs[i] + '_' + s] = xt * z[s]\n",
    "    z_all = pd.concat([z_all,z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:16:28.028681Z",
     "start_time": "2022-01-26T23:16:28.024681Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_3 = ['rank_bm','rank_mvel1','rank_mom12m','rank_mom1m','rank_mom36m','rank_mom6m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:04.969408Z",
     "start_time": "2022-01-26T23:16:29.528767Z"
    }
   },
   "outputs": [],
   "source": [
    "z_3 = pd.DataFrame()\n",
    "for m in df_rank.groupby('DATE'):\n",
    "    z = pd.DataFrame(m[1])\n",
    "    month = z['DATE'].unique()[0]\n",
    "    for i in range(8):\n",
    "        xt = macro.loc[macro['yyyymm'] == int(month),mvs[i]].values[0]\n",
    "        for s in cols_3 :\n",
    "            z[mvs[i] + '_' + s] = xt * z[s]\n",
    "    z_3 = pd.concat([z_3,z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造行业虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:05.033411Z",
     "start_time": "2022-01-26T23:30:04.971408Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sic = df[['permno','DATE','sic2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:09.219651Z",
     "start_time": "2022-01-26T23:30:05.035411Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sic = df_sic[df_sic['DATE']>=19750101].copy()\n",
    "df_sic['DATE'] = df_sic['DATE'].astype(str).str.slice(start = 0, stop = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:09.716679Z",
     "start_time": "2022-01-26T23:30:09.221651Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sic['DATE'] = df_sic['DATE'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:32.840002Z",
     "start_time": "2022-01-26T23:30:09.718679Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加入描述行业的变量sic2\n",
    "z_all = pd.merge(z_all,df_sic,on = ['permno','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:38.086302Z",
     "start_time": "2022-01-26T23:30:32.841002Z"
    }
   },
   "outputs": [],
   "source": [
    "z_3 = pd.merge(z_3,df_sic,on = ['permno','DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:38.367318Z",
     "start_time": "2022-01-26T23:30:38.087302Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造74个虚拟变量\n",
    "indus_d = pd.get_dummies(z_all['sic2'], prefix='industry' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:30:38.688336Z",
     "start_time": "2022-01-26T23:30:38.369318Z"
    }
   },
   "outputs": [],
   "source": [
    "indus_d3 = pd.get_dummies(z_3['sic2'], prefix='industry' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:31:37.306689Z",
     "start_time": "2022-01-26T23:30:38.690336Z"
    }
   },
   "outputs": [],
   "source": [
    "z_all = pd.concat([z_all,indus_d],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:31:47.949298Z",
     "start_time": "2022-01-26T23:31:37.309689Z"
    }
   },
   "outputs": [],
   "source": [
    "z_3 = pd.concat([z_3,indus_d3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:31:47.953298Z",
     "start_time": "2022-01-26T23:31:47.950298Z"
    }
   },
   "outputs": [],
   "source": [
    "z_col = z_all.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:31:47.964299Z",
     "start_time": "2022-01-26T23:31:47.954298Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list(set(z_col)-set(['DATE','permno','rank_RET','sic2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:31:47.976299Z",
     "start_time": "2022-01-26T23:31:47.965299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "920"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:31:47.985300Z",
     "start_time": "2022-01-26T23:31:47.977299Z"
    }
   },
   "outputs": [],
   "source": [
    "z3_col = z_3.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:34:44.433392Z",
     "start_time": "2022-01-26T23:34:44.430392Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_3 = list(set(z3_col)-set(['DATE','permno','rank_RET','sic2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:34:51.348788Z",
     "start_time": "2022-01-26T23:34:50.415734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>rank_roavol</th>\n",
       "      <th>rank_retvol</th>\n",
       "      <th>rank_grltnoa</th>\n",
       "      <th>rank_sp</th>\n",
       "      <th>rank_RET</th>\n",
       "      <th>rank_lgr</th>\n",
       "      <th>rank_depr</th>\n",
       "      <th>rank_roic</th>\n",
       "      <th>...</th>\n",
       "      <th>industry_79.0</th>\n",
       "      <th>industry_80.0</th>\n",
       "      <th>industry_81.0</th>\n",
       "      <th>industry_82.0</th>\n",
       "      <th>industry_83.0</th>\n",
       "      <th>industry_84.0</th>\n",
       "      <th>industry_86.0</th>\n",
       "      <th>industry_87.0</th>\n",
       "      <th>industry_89.0</th>\n",
       "      <th>industry_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.602465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>0.462989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.453519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.938391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10050</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.913553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.994271</td>\n",
       "      <td>-0.828046</td>\n",
       "      <td>0.957022</td>\n",
       "      <td>-0.863580</td>\n",
       "      <td>0.307832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10057</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>0.284535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.149425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10065</td>\n",
       "      <td>197501</td>\n",
       "      <td>0.009809</td>\n",
       "      <td>-0.553432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010026</td>\n",
       "      <td>-0.776552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559500</th>\n",
       "      <td>93423</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.373540</td>\n",
       "      <td>0.897488</td>\n",
       "      <td>0.409608</td>\n",
       "      <td>-0.327794</td>\n",
       "      <td>0.370106</td>\n",
       "      <td>0.787078</td>\n",
       "      <td>0.496326</td>\n",
       "      <td>-0.817325</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559501</th>\n",
       "      <td>93426</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.616928</td>\n",
       "      <td>-0.525917</td>\n",
       "      <td>0.034575</td>\n",
       "      <td>0.596868</td>\n",
       "      <td>-0.836777</td>\n",
       "      <td>-0.932165</td>\n",
       "      <td>-0.533107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559502</th>\n",
       "      <td>93427</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>0.423032</td>\n",
       "      <td>0.178255</td>\n",
       "      <td>0.116591</td>\n",
       "      <td>-0.559755</td>\n",
       "      <td>-0.943500</td>\n",
       "      <td>0.884115</td>\n",
       "      <td>-0.700079</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559503</th>\n",
       "      <td>93434</td>\n",
       "      <td>202012</td>\n",
       "      <td>-0.740288</td>\n",
       "      <td>-0.490137</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>-0.022246</td>\n",
       "      <td>-0.189990</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559504</th>\n",
       "      <td>93436</td>\n",
       "      <td>202012</td>\n",
       "      <td>0.507199</td>\n",
       "      <td>0.154274</td>\n",
       "      <td>-0.004425</td>\n",
       "      <td>-0.022246</td>\n",
       "      <td>-0.356486</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>0.007914</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3559505 rows × 924 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         permno    DATE  rank_roavol  rank_retvol  rank_grltnoa   rank_sp  \\\n",
       "0         10006  197501     0.009809     0.602465      0.000000  0.010026   \n",
       "1         10014  197501     0.009809    -0.453519      0.000000  0.010026   \n",
       "2         10050  197501     0.009809     0.913553      1.000000 -0.994271   \n",
       "3         10057  197501     0.009809     0.284535      0.000000  0.010026   \n",
       "4         10065  197501     0.009809    -0.553432      0.000000  0.010026   \n",
       "...         ...     ...          ...          ...           ...       ...   \n",
       "3559500   93423  202012     0.373540     0.897488      0.409608 -0.327794   \n",
       "3559501   93426  202012     0.010052     0.616928     -0.525917  0.034575   \n",
       "3559502   93427  202012     0.010052     0.423032      0.178255  0.116591   \n",
       "3559503   93434  202012    -0.740288    -0.490137     -0.004425 -0.022246   \n",
       "3559504   93436  202012     0.507199     0.154274     -0.004425 -0.022246   \n",
       "\n",
       "         rank_RET  rank_lgr  rank_depr  rank_roic  ...  industry_79.0  \\\n",
       "0        0.462989  0.000000   0.011728   0.000000  ...              0   \n",
       "1       -0.938391  0.000000   0.011728   0.000000  ...              0   \n",
       "2       -0.828046  0.957022  -0.863580   0.307832  ...              0   \n",
       "3       -0.149425  0.000000   0.011728   0.000000  ...              0   \n",
       "4       -0.776552  0.000000   0.011728   0.000000  ...              0   \n",
       "...           ...       ...        ...        ...  ...            ...   \n",
       "3559500  0.370106  0.787078   0.496326  -0.817325  ...              1   \n",
       "3559501  0.596868 -0.836777  -0.932165  -0.533107  ...              0   \n",
       "3559502 -0.559755 -0.943500   0.884115  -0.700079  ...              0   \n",
       "3559503 -0.189990 -0.001308   0.007914   0.004449  ...              0   \n",
       "3559504 -0.356486 -0.001308   0.007914   0.004449  ...              0   \n",
       "\n",
       "         industry_80.0  industry_81.0  industry_82.0  industry_83.0  \\\n",
       "0                    0              0              0              0   \n",
       "1                    0              0              0              0   \n",
       "2                    0              0              0              0   \n",
       "3                    0              0              0              0   \n",
       "4                    0              0              0              0   \n",
       "...                ...            ...            ...            ...   \n",
       "3559500              0              0              0              0   \n",
       "3559501              0              0              0              0   \n",
       "3559502              0              0              0              0   \n",
       "3559503              0              0              0              0   \n",
       "3559504              0              0              0              0   \n",
       "\n",
       "         industry_84.0  industry_86.0  industry_87.0  industry_89.0  \\\n",
       "0                    0              0              0              0   \n",
       "1                    0              0              0              0   \n",
       "2                    0              0              0              0   \n",
       "3                    0              0              0              0   \n",
       "4                    0              0              0              0   \n",
       "...                ...            ...            ...            ...   \n",
       "3559500              0              0              0              0   \n",
       "3559501              0              0              0              0   \n",
       "3559502              0              0              0              0   \n",
       "3559503              0              0              0              0   \n",
       "3559504              0              0              0              0   \n",
       "\n",
       "         industry_99.0  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "3559500              0  \n",
       "3559501              0  \n",
       "3559502              0  \n",
       "3559503              0  \n",
       "3559504              0  \n",
       "\n",
       "[3559505 rows x 924 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:34:59.230238Z",
     "start_time": "2022-01-26T23:34:59.222238Z"
    }
   },
   "outputs": [],
   "source": [
    "macro['yyyymm'] = pd.to_datetime(macro['yyyymm'],format = '%Y%m').dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:35:00.166292Z",
     "start_time": "2022-01-26T23:34:59.696265Z"
    }
   },
   "outputs": [],
   "source": [
    "z_all['DATE'] = pd.to_datetime(z_all['DATE'].astype(int),format='%Y%m').dt.to_period('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:35:00.684322Z",
     "start_time": "2022-01-26T23:35:00.168292Z"
    }
   },
   "outputs": [],
   "source": [
    "z_all['year'] = z_all['DATE'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:35:26.627805Z",
     "start_time": "2022-01-26T23:35:26.456796Z"
    }
   },
   "outputs": [],
   "source": [
    "time_idx = [value for (key, value) in sorted(z_all.groupby('DATE').groups.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:35:28.000884Z",
     "start_time": "2022-01-26T23:35:27.996884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:35:29.947995Z",
     "start_time": "2022-01-26T23:35:29.943995Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义函数list_flat，效果为展开list\n",
    "def list_flat(list_):\n",
    "    return [item for sublist in list_ for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-27T02:11:24.054020Z",
     "start_time": "2022-01-27T02:10:45.653823Z"
    }
   },
   "outputs": [],
   "source": [
    "# training, validation, testing scheme:\n",
    "# 1. [1975-1987], [1988-1996], [1997]\n",
    "# 2. [1975-1988], [1989-1997], [1998]\n",
    "# ...\n",
    "# last. [1975-2010], [2011-2019], [2020]\n",
    "fulltrain_idx = []\n",
    "cv_idx = []\n",
    "test_idx = []\n",
    "for i in range(13,len(time_idx)-9):\n",
    "    train_idx = list_flat(time_idx[0:i])\n",
    "    val_idx = list_flat(time_idx[i:i+9])\n",
    "    fulltrain_idx.append(train_idx + val_idx)\n",
    "    cv_idx.append((np.where(np.isin(fulltrain_idx[-1], train_idx))[0],\n",
    "                   np.where(np.isin(fulltrain_idx[-1], val_idx))[0]))\n",
    "    test_idx.append(time_idx[i+9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T14:53:53.899558Z",
     "start_time": "2022-01-28T14:53:53.896558Z"
    }
   },
   "outputs": [],
   "source": [
    "test_years = list(range(1997,2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:36:12.347420Z",
     "start_time": "2022-01-26T23:36:12.344420Z"
    }
   },
   "outputs": [],
   "source": [
    "def r2_oos(y_true, y_pred):\n",
    "    return 1 - np.sum((y_true - y_pred)**2) / np.sum(y_true**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:36:12.363421Z",
     "start_time": "2022-01-26T23:36:12.348421Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_oos_scorer = make_scorer(r2_oos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:36:19.012802Z",
     "start_time": "2022-01-26T23:36:19.009802Z"
    }
   },
   "outputs": [],
   "source": [
    "model = HuberRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T23:36:19.589835Z",
     "start_time": "2022-01-26T23:36:19.586835Z"
    }
   },
   "outputs": [],
   "source": [
    "y_t_a = []\n",
    "y_p_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T07:54:52.611559Z",
     "start_time": "2022-01-27T02:11:37.342780Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.013998117059558557\n",
      "aggregate : 0.013998117059558557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1998 : -0.0022164448242143475\n",
      "aggregate : 0.005890920747928963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1999 : -0.022957361011483712\n",
      "aggregate : -0.0032538243252375754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2000 : 0.0190390785152047\n",
      "aggregate : 0.0019502857372922788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2001 : -0.0036669091241854357\n",
      "aggregate : 0.0009050785796766991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2002 : 0.013874547355409161\n",
      "aggregate : 0.0028281226376374313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2003 : -0.027821415516855907\n",
      "aggregate : -0.0009260962687402952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2004 : -0.005242613362441473\n",
      "aggregate : -0.001388524328693963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2005 : 0.0010125772530301669\n",
      "aggregate : -0.0011544902413371805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2006 : -0.0077635577460817284\n",
      "aggregate : -0.0017409625116890926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2007 : -0.007272990643842903\n",
      "aggregate : -0.0021986484756668645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2008 : -0.0036512155305474803\n",
      "aggregate : -0.002305722069309013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2009 : -0.036765669553306735\n",
      "aggregate : -0.004444276755864562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2010 : -0.013913295563166006\n",
      "aggregate : -0.004981235650694638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2011 : 0.003432070781076879\n",
      "aggregate : -0.004535070076277847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2012 : -0.005240267648414232\n",
      "aggregate : -0.0045700939907682425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2013 : -0.005663354691478828\n",
      "aggregate : -0.00462119863077759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2014 : 0.001679139926204054\n",
      "aggregate : -0.004331928531139839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2015 : -0.0010037472785080492\n",
      "aggregate : -0.004182769750933568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2016 : 0.005415929037166922\n",
      "aggregate : -0.0037747488609696234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2017 : -0.00365241643829739\n",
      "aggregate : -0.003769796486237542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2018 : 0.0004910806152111924\n",
      "aggregate : -0.0036023099373108103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2019 : -0.0005762233824573304\n",
      "aggregate : -0.003487237268915644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38728/62961917.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test year\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_years\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr2_oos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0my_t_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0my_p_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_all.loc[fulltrain_idx[i], cols]\n",
    "    y_fulltrain = z_all.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_all.loc[test_idx[i], cols]\n",
    "    y_test = z_all.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X=X_fulltrain, y=y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    \n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    y_t_a.extend(y_test.tolist())\n",
    "    y_p_a.extend(y_pred.tolist())\n",
    "    print(\"aggregate\",\":\",r2_oos(y_true=np.array(y_t_a), y_pred=np.array(y_p_a)))\n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"OLS\",\":\",mean)\n",
    "print(\"OLS aggregate\",\":\",r2_oos(y_true=np.array(y_t_a), y_pred=np.array(y_p_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T08:23:15.701970Z",
     "start_time": "2022-01-28T08:23:15.485958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS aggregate : -0.003487237268915644\n"
     ]
    }
   ],
   "source": [
    "print(\"OLS aggregate\",\":\",r2_oos(y_true=np.array(y_t_a), y_pred=np.array(y_p_a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T08:23:19.262174Z",
     "start_time": "2022-01-28T08:23:19.196170Z"
    }
   },
   "outputs": [],
   "source": [
    "y_t_a = []\n",
    "y_p_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T14:43:33.297062Z",
     "start_time": "2022-01-28T08:23:53.897155Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.013671811560874714\n",
      "aggregate : 0.013671811560874714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1998 : 0.00182557743509848\n",
      "aggregate : 0.007748756328200601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1999 : -0.021918470147207936\n",
      "aggregate : -0.0016555896709151696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2000 : 0.016833549878333742\n",
      "aggregate : 0.002660560534575751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2001 : -0.005283038362110748\n",
      "aggregate : 0.0011824728718192734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2002 : 0.011414196953387967\n",
      "aggregate : 0.0026995786637364905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2003 : -0.03012257330250878\n",
      "aggregate : -0.0013207606587866128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2004 : -0.006311380819007395\n",
      "aggregate : -0.0018554053152444183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2005 : -0.0006752151770577086\n",
      "aggregate : -0.0017403728134957053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2006 : -0.004885820279309616\n",
      "aggregate : -0.002019492025884251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2007 : -0.008012394724489003\n",
      "aggregate : -0.002515307915303522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2008 : 0.0029973665391621607\n",
      "aggregate : -0.0021089501761277774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2009 : -0.02256818058217558\n",
      "aggregate : -0.0033786324090592235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2010 : -0.013111889197903182\n",
      "aggregate : -0.003930575426048355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2011 : 0.003121721842251013\n",
      "aggregate : -0.00355658545109816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2012 : -0.004233761559752969\n",
      "aggregate : -0.0035902176685953524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2013 : -0.006967199684956515\n",
      "aggregate : -0.0037480752135996553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2014 : 0.0003059757602162927\n",
      "aggregate : -0.0035619398625348353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2015 : -0.0026157348557989124\n",
      "aggregate : -0.003519533883437953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2016 : 0.002386611293473506\n",
      "aggregate : -0.0032684758322856222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2017 : -0.006574736538955683\n",
      "aggregate : -0.0034023229483950423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 2018 : -0.001658951637463879\n",
      "aggregate : -0.0033337945122504653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2323\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38728/2706664737.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0my_p_a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test year\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_years\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr2_oos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"aggregate\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr2_oos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_p_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr2_oos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_3.loc[fulltrain_idx[i], cols_3]\n",
    "    y_fulltrain = z_3.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_3.loc[test_idx[i], cols_3]\n",
    "    y_test = z_3.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X=X_fulltrain, y=y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    y_t_a.extend(y_test.tolist())\n",
    "    y_p_a.extend(y_pred.tolist())\n",
    " \n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    print(\"aggregate\",\":\",r2_oos(y_true=np.array(y_t_a), y_pred=np.array(y_p_a)))  \n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"OLS_3\",\":\",mean)\n",
    "print(\"OLS_3 aggregate\",\":\",r2_oos(y_true=np.array(y_t_a), y_pred=np.array(y_p_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T14:54:08.795410Z",
     "start_time": "2022-01-28T14:54:08.791410Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PLSRegression(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:46:04.614533Z",
     "start_time": "2022-01-28T14:54:09.683461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.016889419269000894\n",
      "Test year 1998 : 0.009042339374591424\n",
      "Test year 1999 : -0.004078112241480358\n",
      "Test year 2000 : 0.01787054107503261\n",
      "Test year 2001 : 0.0040469195081989096\n",
      "Test year 2002 : 0.01604553045534629\n",
      "Test year 2003 : -0.009634442305096247\n",
      "Test year 2004 : 0.0008571580266319989\n",
      "Test year 2005 : 0.003547362518705466\n",
      "Test year 2006 : 0.0007128579755623088\n",
      "Test year 2007 : 0.0005471454797906228\n",
      "Test year 2008 : 0.010734378491270347\n",
      "Test year 2009 : -0.012708852886117672\n",
      "Test year 2010 : -0.001906448117200199\n",
      "Test year 2011 : 0.007017960917327315\n",
      "Test year 2012 : 0.0016571071936668513\n",
      "Test year 2013 : 0.002170745426630205\n",
      "Test year 2014 : 0.004790673315781979\n",
      "Test year 2015 : 0.004809878849562632\n",
      "Test year 2016 : 0.006407269055004328\n",
      "Test year 2017 : 0.0028198366678839903\n",
      "Test year 2018 : 0.005414018593980607\n",
      "Test year 2019 : 0.004120704592366353\n",
      "Test year 2020 : -0.006860516786773241\n",
      "PLS : 0.003513061435402809\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_all.loc[fulltrain_idx[i], cols]\n",
    "    y_fulltrain = z_all.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_all.loc[test_idx[i], cols]\n",
    "    y_test = z_all.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X_fulltrain, y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"PLS\",\":\",mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:46:04.635534Z",
     "start_time": "2022-01-28T16:46:04.616533Z"
    }
   },
   "outputs": [],
   "source": [
    "class PCARegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_components = 20):\n",
    "        self.n_components = n_components\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.pca_ = PCA(n_components=self.n_components).fit(X)\n",
    "        self.X_ = self.pca_.transform(X)\n",
    "        self.reg_ = LinearRegression().fit(self.X_,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.pred_ = self.reg_.predict(self.pca_.transform(X))\n",
    "        return self.pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T16:46:04.673537Z",
     "start_time": "2022-01-28T16:46:04.637535Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PCARegressor(n_components = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T18:32:48.678825Z",
     "start_time": "2022-01-28T16:46:04.675537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.01741402959351801\n",
      "Test year 1998 : 0.007289512438936052\n",
      "Test year 1999 : -0.009760523573540514\n",
      "Test year 2000 : 0.018003523080425854\n",
      "Test year 2001 : 0.003070150638721292\n",
      "Test year 2002 : 0.01565086073891464\n",
      "Test year 2003 : -0.01462289039388498\n",
      "Test year 2004 : -0.0006406516815353758\n",
      "Test year 2005 : 0.0029859270355776513\n",
      "Test year 2006 : 0.00040427851123647773\n",
      "Test year 2007 : -0.001831910897968747\n",
      "Test year 2008 : 0.006429940935999134\n",
      "Test year 2009 : -0.012853286825344146\n",
      "Test year 2010 : -0.0046635474173621905\n",
      "Test year 2011 : 0.004799745125141808\n",
      "Test year 2012 : 0.00026832472652293937\n",
      "Test year 2013 : -0.0005659363387475747\n",
      "Test year 2014 : 0.0033510332655366515\n",
      "Test year 2015 : 0.0022221545289753397\n",
      "Test year 2016 : 0.005678839622700438\n",
      "Test year 2017 : -0.001796161229351112\n",
      "Test year 2018 : 0.0011177045398840235\n",
      "Test year 2019 : 0.0011847574286772966\n",
      "Test year 2020 : -0.009146245375149631\n",
      "PCR : 0.0014162345199118058\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_all.loc[fulltrain_idx[i], cols]\n",
    "    y_fulltrain = z_all.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_all.loc[test_idx[i], cols]\n",
    "    y_test = z_all.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X_fulltrain, y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"PCR\",\":\",mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T06:17:39.166702Z",
     "start_time": "2022-01-29T06:17:39.162702Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(penalty='elasticnet',alpha=0.1,l1_ratio=0.3,loss='huber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T08:11:20.531862Z",
     "start_time": "2022-01-29T06:17:40.337769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.0005433382097667083\n",
      "Test year 1998 : -0.001208176866767996\n",
      "Test year 1999 : -0.0068464251253925745\n",
      "Test year 2000 : -0.002850178365361611\n",
      "Test year 2001 : -0.012711930489251788\n",
      "Test year 2002 : -0.01229313683040556\n",
      "Test year 2003 : -0.012718262152196624\n",
      "Test year 2004 : -0.012858220605869386\n",
      "Test year 2005 : -0.011683813778632812\n",
      "Test year 2006 : -0.01175256657135293\n",
      "Test year 2007 : -0.010514654513841926\n",
      "Test year 2008 : -0.009407859999874368\n",
      "Test year 2009 : -0.009861615940990998\n",
      "Test year 2010 : -0.010036297912340064\n",
      "Test year 2011 : -0.008220158178825043\n",
      "Test year 2012 : -0.007805604568120295\n",
      "Test year 2013 : -0.00796391480048042\n",
      "Test year 2014 : -0.00760009782589921\n",
      "Test year 2015 : -0.007433192382495957\n",
      "Test year 2016 : -0.00677029472187618\n",
      "Test year 2017 : -0.006139005084699223\n",
      "Test year 2018 : -0.008316497123836974\n",
      "Test year 2019 : -0.006383944512353246\n",
      "Test year 2020 : -0.0069141310340492534\n",
      "ENet : -0.008239443382297823\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_all.loc[fulltrain_idx[i], cols]\n",
    "    y_fulltrain = z_all.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_all.loc[test_idx[i], cols]\n",
    "    y_test = z_all.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X_fulltrain, y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"ENet\",\":\",mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized linear model with group lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T20:25:41.908231Z",
     "start_time": "2022-01-28T20:25:41.905231Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SGDRegressor(penalty='l1',alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T22:30:04.639075Z",
     "start_time": "2022-01-28T20:25:41.909231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.01058828909123033\n",
      "Test year 1998 : 0.003777811810396825\n",
      "Test year 1999 : -0.01675517048520203\n",
      "Test year 2000 : 0.014549229323612356\n",
      "Test year 2001 : 0.0029155549885113707\n",
      "Test year 2002 : 0.004177818192303562\n",
      "Test year 2003 : -0.03212577329868482\n",
      "Test year 2004 : -0.002596122116116595\n",
      "Test year 2005 : 0.004413458981639029\n",
      "Test year 2006 : -0.0015118443077726251\n",
      "Test year 2007 : -0.0032462406395017407\n",
      "Test year 2008 : 0.0031742715756993833\n",
      "Test year 2009 : -0.006103736356814382\n",
      "Test year 2010 : -0.0007527596743808207\n",
      "Test year 2011 : 0.0007193978703921022\n",
      "Test year 2012 : -0.0020625467772359407\n",
      "Test year 2013 : -0.0007483122311391366\n",
      "Test year 2014 : -0.0038909566367282267\n",
      "Test year 2015 : -0.017716285044635516\n",
      "Test year 2016 : 0.0016917965854962302\n",
      "Test year 2017 : -0.0007366588861272838\n",
      "Test year 2018 : 0.0033601169949833976\n",
      "Test year 2019 : 0.0016185872146823321\n",
      "Test year 2020 : -0.009721508615487817\n",
      "GLM : -0.0019575659350366675\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_all.loc[fulltrain_idx[i], cols]\n",
    "    y_fulltrain = z_all.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_all.loc[test_idx[i], cols]\n",
    "    y_test = z_all.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X_fulltrain, y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"GLM\",\":\",mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-28T22:30:04.644075Z",
     "start_time": "2022-01-28T22:30:04.641075Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state = 42, n_estimators = 100, max_depth = 3, max_features = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T02:36:52.527038Z",
     "start_time": "2022-01-28T22:58:58.450243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test year 1997 : 0.01117863716005385\n",
      "Test year 1998 : 0.007737098641032891\n",
      "Test year 1999 : -0.0014309072827465297\n",
      "Test year 2000 : 0.007817772036542436\n",
      "Test year 2001 : 0.0007104580111424452\n",
      "Test year 2002 : 0.0060693993830475135\n",
      "Test year 2003 : -0.006268558911345368\n",
      "Test year 2004 : -0.00024917254324496874\n",
      "Test year 2005 : 0.0011160545200560312\n",
      "Test year 2006 : -8.413794630146576e-05\n",
      "Test year 2007 : -0.0005979540324174693\n",
      "Test year 2008 : 0.0022981686073837437\n",
      "Test year 2009 : -0.0035655310460074308\n",
      "Test year 2010 : -0.0021069174857548667\n",
      "Test year 2011 : 0.002408296885740735\n",
      "Test year 2012 : 0.00016909646533380673\n",
      "Test year 2013 : -0.00031303297672558017\n",
      "Test year 2014 : 0.0016540913752470798\n",
      "Test year 2015 : 0.001503009132044375\n",
      "Test year 2016 : 0.002550762773775306\n",
      "Test year 2017 : 0.001062838476646344\n",
      "Test year 2018 : 0.002223709878073299\n",
      "Test year 2019 : 0.0011725605257082439\n",
      "Test year 2020 : -0.0020493152532425896\n",
      "RF : 0.0013752677664184098\n"
     ]
    }
   ],
   "source": [
    "sum = 0.0\n",
    "\n",
    "for i in range(len(fulltrain_idx)):\n",
    "    X_fulltrain = z_all.loc[fulltrain_idx[i], cols]\n",
    "    y_fulltrain = z_all.loc[fulltrain_idx[i], 'rank_RET']\n",
    "    X_test = z_all.loc[test_idx[i], cols]\n",
    "    y_test = z_all.loc[test_idx[i], 'rank_RET']\n",
    "    \n",
    "    model.fit(X_fulltrain, y_fulltrain)\n",
    "    y_pred = model.predict(X=X_test)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "    print(\"Test year\", test_years[i],\":\",r2_oos(y_true=y_test, y_pred=y_pred))\n",
    "    sum = sum + r2_oos(y_true=y_test, y_pred=y_pred)\n",
    "mean = sum/24\n",
    "print(\"RF\",\":\",mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
