{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:46:48.352441Z",
     "start_time": "2022-05-04T07:46:48.336553Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 9.0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor, SGDRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "# import lightgbm as lgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.mlab as mlab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T06:54:34.916408Z",
     "start_time": "2022-05-04T06:54:34.912440Z"
    }
   },
   "outputs": [],
   "source": [
    "n_inputs = 920\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:11:03.783136Z",
     "start_time": "2022-05-04T10:11:03.773216Z"
    }
   },
   "outputs": [],
   "source": [
    "n_inputs = 920\n",
    "def preprocess_mean(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    y_mean = np.mean(y)\n",
    "    return y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:31:48.990314Z",
     "start_time": "2022-05-04T07:31:48.978869Z"
    }
   },
   "outputs": [],
   "source": [
    "def csv_reader_dataset_train(filepaths, repeat=1, n_readers=13,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:26:05.546085Z",
     "start_time": "2022-05-04T10:26:05.535636Z"
    }
   },
   "outputs": [],
   "source": [
    "def csv_reader_dataset_train_mean(filepaths, repeat=1, n_readers=13,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.map(preprocess_mean, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:59:03.117263Z",
     "start_time": "2022-05-04T08:59:03.092946Z"
    }
   },
   "outputs": [],
   "source": [
    "def csv_reader_dataset_val(filepaths, repeat=1, n_readers=9,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T09:12:40.619242Z",
     "start_time": "2022-05-04T09:12:40.607833Z"
    }
   },
   "outputs": [],
   "source": [
    "def csv_reader_dataset_test(filepaths, repeat=1, n_readers=1,\n",
    "                       n_read_threads=None, shuffle_buffer_size=1,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:32:58.234706Z",
     "start_time": "2022-05-04T07:32:58.218914Z"
    }
   },
   "outputs": [],
   "source": [
    "train_filepaths = \"../../920data/train/df_%s.csv\"\n",
    "\n",
    "valid_filepaths = \"../../920data/val/df_*.csv\"\n",
    "\n",
    "test_filepaths = \"../../920data/df_1997.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:34:13.106027Z",
     "start_time": "2022-05-04T07:34:11.318595Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset_train(train_filepaths)\n",
    "\n",
    "valid_set = csv_reader_dataset_val(valid_filepaths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:15:57.852429Z",
     "start_time": "2022-05-04T10:15:57.847006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((None, 920), (None, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:29:09.926479Z",
     "start_time": "2022-05-04T10:29:09.916555Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_mean = csv_reader_dataset_train_mean(train_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T09:12:45.299116Z",
     "start_time": "2022-05-04T09:12:44.479502Z"
    }
   },
   "outputs": [],
   "source": [
    "test_set = csv_reader_dataset_test(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:48:15.340490Z",
     "start_time": "2022-05-04T07:48:15.248939Z"
    }
   },
   "outputs": [],
   "source": [
    "nn1_model = keras.models.Sequential()\n",
    "nn1_model.add(keras.layers.InputLayer(input_shape=[920]))\n",
    "nn1_model.add(keras.layers.BatchNormalization())\n",
    "nn1_model.add(keras.layers.Dense(32, activation='relu'))\n",
    "nn1_model.add(keras.layers.BatchNormalization())\n",
    "nn1_model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:48:29.619225Z",
     "start_time": "2022-05-04T07:48:29.595782Z"
    }
   },
   "outputs": [],
   "source": [
    "nn1_model.compile(loss='mse',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:42:54.115109Z",
     "start_time": "2022-05-04T07:48:47.882495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26788/26788 [==============================] - 350s 13ms/step - loss: 0.3163 - val_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "26788/26788 [==============================] - 327s 12ms/step - loss: 0.3095 - val_loss: 0.3433\n",
      "Epoch 3/10\n",
      "26788/26788 [==============================] - 321s 12ms/step - loss: 0.3087 - val_loss: 0.3367\n",
      "Epoch 4/10\n",
      "26788/26788 [==============================] - 321s 12ms/step - loss: 0.3081 - val_loss: 0.3401\n",
      "Epoch 5/10\n",
      "26788/26788 [==============================] - 321s 12ms/step - loss: 0.3075 - val_loss: 0.3360\n",
      "Epoch 6/10\n",
      "26788/26788 [==============================] - 318s 12ms/step - loss: 0.3072 - val_loss: 0.3438\n",
      "Epoch 7/10\n",
      "26788/26788 [==============================] - 322s 12ms/step - loss: 0.3070 - val_loss: 0.3477\n",
      "Epoch 8/10\n",
      "26788/26788 [==============================] - 324s 12ms/step - loss: 0.3066 - val_loss: 0.3595\n",
      "Epoch 9/10\n",
      "26788/26788 [==============================] - 322s 12ms/step - loss: 0.3066 - val_loss: 0.3460\n",
      "Epoch 10/10\n",
      "26788/26788 [==============================] - 320s 12ms/step - loss: 0.3063 - val_loss: 0.3541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22cacb8fb70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1_model.fit(train_set, epochs=10, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T09:13:08.784327Z",
     "start_time": "2022-05-04T09:12:49.597465Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = nn1_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:03:29.858972Z",
     "start_time": "2022-05-04T10:03:29.841583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01991238, -0.2699778 , -0.3973542 , ..., -0.21251288,\n",
       "        -0.06760653, -0.21158417]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:03:54.367513Z",
     "start_time": "2022-05-04T10:03:54.353592Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred1 = y_pred[0:10000].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:03:58.506411Z",
     "start_time": "2022-05-04T10:03:58.493546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01991238, -0.2699778 , -0.3973542 , ..., -0.06563534,\n",
       "        -0.16934478, -0.05159641]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:51:17.792476Z",
     "start_time": "2022-05-04T08:51:17.780501Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"../../920data/df_1997.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:52:11.537702Z",
     "start_time": "2022-05-04T08:51:33.808601Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(filename,'rt') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    column = [row['ret'] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:04:09.195400Z",
     "start_time": "2022-05-04T10:04:09.139317Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true = np.array(column,dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:04:13.313326Z",
     "start_time": "2022-05-04T10:04:13.304425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07082833, -0.8619448 , -0.889956  , ...,  0.73478264,\n",
       "       -0.21605352, -0.42341137], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:04:15.671963Z",
     "start_time": "2022-05-04T10:04:15.653535Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true1 = y_ture[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:54:39.271933Z",
     "start_time": "2022-05-04T08:54:39.266476Z"
    }
   },
   "outputs": [],
   "source": [
    "def r2_oos(y_true, y_pred):\n",
    "    return 1 - np.sum((y_true - y_pred)**2) / np.sum(y_true**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:04:17.243498Z",
     "start_time": "2022-05-04T10:04:17.233082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.301563024520874"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_oos(y_true=y_true1, y_pred=y_pred1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
